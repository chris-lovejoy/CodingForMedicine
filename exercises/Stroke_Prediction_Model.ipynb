{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Strokes from Admission Data\n",
    "\n",
    "In this exercise we are going to try to predict strokes from admission data with various models, and learn how to deal with the issue of class imbalance.\n",
    "\n",
    "Uses the [stroke dataset from Kaggle](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset) along with the `sklearn` and `pandas` packages!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Downloading and Importing Data\n",
    "To begin with, let's setup our notebook with the necessary packages as well as grab the data from Kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Establish venv/conda/package environment\n",
    "# Commands with `%` run in the command line instead of within python so we don't have to do this within a seperate terminal!\n",
    "# In this case, we are making sure our environment/colab instance has installed the latest versions of several commonly used data science packages\n",
    "%pip install pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup matplotlib to display plots correctly within pandas\n",
    "%matplotlib inline\n",
    "\n",
    "# Import packages into our runtime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download from Kaggle\n",
    "\n",
    "Those who have downloaded and setup the kaggle CLI (Command Line Interface) can run the following command to download the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the stroke prediction dataset into the ./data folder\n",
    "!kaggle datasets download -d fedesoriano/stroke-prediction-dataset --path ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Exploration\n",
    "Now we have the data downloaded, we need to load this into a dataframe so we can explore it, and perform further analysis.\n",
    "\n",
    "We can either do this by unzipping the dataset or just loading it directly with pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to unzip the file - we can load the .csv file within directly into a DataFrame (commonly notated as `df`)\n",
    "df = pd.read_csv(\"./data/stroke-prediction-dataset.zip\")\n",
    "df = df.rename({\"Residence_type\": \"residence_type\"}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good practice to explore what data we are actually dealing with and get a *feel* for it. We should check for missing data, what data is present, and relevant datatypes!\n",
    "\n",
    "There are many ways of doing this with `pandas` ([API](https://pandas.pydata.org/docs/reference/frame.html#attributes-and-underlying-data)) - the most useful and commonly used methods being `head()`, `info()`, `describe()` initially:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at the first 10 entries of the dataset\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe is useful for looking at continuous data (i.e. int or float datatypes) - we can see it also has a look at data which is\n",
    "# stored as booleans, as well as ID's (i.e. the id, hypertension, heart_disease, and stroke coluns)\n",
    "\n",
    "# We can see\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can exclude the boolean or ID data by selecting certain rows for example\n",
    "\n",
    "df[[\"age\", \"avg_glucose_level\", \"bmi\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation and Graphing\n",
    "\n",
    "We can explore the data further by looking at the correlation of datasets - in this case using a [Pearson correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient), which looks for **linear** correlations between variables (non-linear correlations will not be identified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr(numeric_only=True)\n",
    "corr.style.background_gradient(cmap=\"coolwarm\").format(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [\"age\", \"avg_glucose_level\", \"bmi\"]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "\n",
    "for idx, feature in enumerate(continuous_features):\n",
    "    sns.histplot(data=df, x=feature, ax=ax[idx], kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stroke\"].value_counts(normalize=True).plot(kind=\"pie\", autopct=\"%.2f\")\n",
    "plt.xlabel(\"Stroke\")\n",
    "plt.ylabel(\"Percentage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the vast majority of our dataset have not had a stroke - infact less than 5% have.\n",
    "\n",
    "We will explore the implications of this later..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrete Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_features = [\"ever_married\", \"work_type\", \"residence_type\", \"smoking_status\"]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(8, 8))\n",
    "\n",
    "for idx, axis in enumerate(fig.axes):\n",
    "    sns.histplot(df[discrete_features[idx]], ax=axis)\n",
    "    axis.tick_params(labelrotation=30)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.ylabel('Average Glucose Level (mg/dl)')\n",
    "# plt.title('Comparing Average Glucose Level to Stroke Class')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"ever_married\", \"stroke\"]).size().unstack().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Preparing our Data for Model Training\n",
    "Now we have a feel for our dataset, we can begin building a useful model to try and predict outcomes\n",
    "\n",
    "### Test-Train Split\n",
    "We need to split our model into training sets (data which the machine learning algorithm uses to learn) and testing sets (used to validate how well our model is working).\n",
    "\n",
    "### Data Pre-processing\n",
    "In order to use our data - we will need to convert how our data is stored in order for machine learning models to interpret it. For example `Male` or `Female` can't be correctly interpreted.\n",
    "\n",
    "Continuous data (i.e. BMI, Average Blood Glucose, and so on) will need to be scaled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we are missing 201 BMI values: at this point we have two options, to either drop the rows which are missing data, or to _impute_ their values. In this case, we will go for the latter!\n",
    "\n",
    "There are more complex approaches to doing this - which can be done using the [`sklearn.imputer`](https://scikit-learn.org/stable/modules/impute.html) classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First calculate the average\n",
    "mean_bmi = df[\"bmi\"].mean()\n",
    "\n",
    "# Now fill missing values with this mean\n",
    "df[\"bmi\"] = df[\"bmi\"].fillna(mean_bmi)\n",
    "\n",
    "# Check that our commands have worked!\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get rid of 'ID' column, this isn't needed!\n",
    "df = df.drop(columns=[\"id\"])\n",
    "\n",
    "# We can then develop our `X` and `y` sets\n",
    "X = df.drop(columns=[\"stroke\"])\n",
    "y = df[\"stroke\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can double check we have the right shape of data - we should have 5110 rows, with 10 features in the X set - and only a column of 1 or 0 in the y column\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfect! Now to split into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numerical_columns = [\"age\", \"avg_glucose_level\", \"bmi\"]\n",
    "ordinal_columns = [\"work_type\", \"smoking_status\"]\n",
    "binary_columns = [\"gender\", \"ever_married\", \"residence_type\"]\n",
    "\n",
    "# These are columns we don't want to modify as they're already in a good form for ML training\n",
    "pass_columns = [\"hypertension\", \"heart_disease\"]\n",
    "\n",
    "\n",
    "numerical_transformer = make_pipeline(StandardScaler())\n",
    "ordinal_transformer = make_pipeline(OneHotEncoder())\n",
    "binary_transformer = make_pipeline(OrdinalEncoder())\n",
    "\n",
    "pipeline = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", numerical_transformer, numerical_columns),\n",
    "        (\"ord\", ordinal_transformer, ordinal_columns),\n",
    "        (\"bin\", binary_transformer, binary_columns),\n",
    "    ],\n",
    "    remainder=\"passthrough\",  # Include those we aren't changing in the pipeline\n",
    ")\n",
    "\n",
    "X_train_prep = pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df = pd.DataFrame(X_train_prep)\n",
    "prep_df.columns = pipeline.get_feature_names_out()\n",
    "prep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to scale the test data which we haven't yet touched\n",
    "# NB: We only TRANSFORM the test date - we don't want to fit our transformers to this data\n",
    "X_test_prep = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Making our First Model\n",
    "\n",
    "Now we have imported, cleaned, and transformed our data - it is finally in a form that we can make models to help us predict future strokes.\n",
    "\n",
    "To begin with, we will use a Logistic Regression to make these predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# TODO: Build first models\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train_prep, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "\n",
    "# we can now predict some strokes in our test dataset - which our model has not seen!\n",
    "y_pred = logistic_regression.predict(X_test_prep)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ¤” Something Fishy Afoot\n",
    "\n",
    "Hmmm... our model has a pretty a pretty good \"accuracy\" - however if we look deeper something odd is going on.\n",
    "\n",
    "Let's have a look at what are model is guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.sum()  # Add's up how many 1's there are (i.e. how many people we have predicted have had a stroke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially our model just guesses `0` / no stroke every time and get's a pretty good accuracy.\n",
    "\n",
    "For imbalanced class problems (a common and important issue in medicine!) we need to dive deeper other metrics are more useful to understand how well our model truly works. You may remember from previous exercises the F1 Score ~ which provides a metric of how well a model is at making true positives/negatives and false positives/negatives. Unfortunately, there will always be a trade off between these - and one we need to keep in mind when designing machine learning models in healthcare.\n",
    "\n",
    "We have to make decisions when we tune our model if we want more *false positives* or more *false negatives* - with real world implications. If we were deploying our model, we would have to decide if we would rather have fewer false positives - and the run risk of missing potential strokes - or predict more people were having strokes (when they aren't), and run the risk of over investigation, radiation exposure, and potentially harmful implications as a result of this.\n",
    "\n",
    "If you would like to learn more about this it is well worth looking at the [Machine Learning University's explainer on Precision and Recall](https://mlu-explain.github.io/precision-recall/) which nicely demonstrates how the precision-recall tradeoff works visually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score: {f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check more complicated models also suffer from the same issue - to check that this isn't purely as a result of [Logistic Regression](https://mlu-explain.github.io/logistic-regression/) being unable to make complicated predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "svm = SVC()\n",
    "forest = RandomForestClassifier()\n",
    "gbm = GradientBoostingClassifier()\n",
    "\n",
    "for model in (svm, forest, gbm):\n",
    "    model.fit(X_train_prep, y_train)\n",
    "    y_pred = model.predict(X_test_prep)\n",
    "\n",
    "    print(f\"F1 Score ({type(model).__name__}): {f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Tackling Unbalanced Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explain problem with unbalanced datasets\n",
    "# TODO: Accuracy paradox --> look at alternative, e.g. F1 score, AUC\n",
    "# TODO: Explore imbalanced-learn package amongst others"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ucl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e6ddcdc73d423b0f01f8ea8dade5820db75de1f7bd936da71df45ce5b0f95b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
