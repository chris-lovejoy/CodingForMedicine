{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5316200d",
   "metadata": {},
   "source": [
    "# Extracting Insights from Medical Research Papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f8c8e",
   "metadata": {},
   "source": [
    "**In this exercise, we will use natural language processing (NLP) to extract key insights from academic medical papers.**\n",
    "\n",
    "We will use the latest GPT model from OpenAI and [a dataset of nearly 200,000 PubMed Articles](https://huggingface.co/datasets/ccdv/pubmed-summarization). We'll first generate a summary of the full article text, then we'll use that summary to generate an abstract and to answer questions about the paper.\n",
    "\n",
    "In this exercise we'll learn how to:\n",
    "\n",
    "- **Perform various NLP tasks**, including abstractive summarisation, extractive summarisation and question-answering\n",
    "- **Prepare large amounts of text data** for use by NLP models\n",
    "- Use OpenAI's GPT **large language model (LLM)**\n",
    "- **Query an API** (Application Program Interface)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e09066",
   "metadata": {},
   "source": [
    "## Part 1: Loading and understanding our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed8a8fa",
   "metadata": {},
   "source": [
    "For this exercise, we're going to use full text versions of academic articles. \n",
    "\n",
    "Because large language models like GPT are trained on ['plain text'](https://en.wikipedia.org/wiki/Plain_text) from the internet, we'll need to ensure that data we're working with is in that format. For example, we can't directly feed in PDF files. And some of the formatting that programs like Word might include will also be unhelpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77961d7f",
   "metadata": {},
   "source": [
    "To make our lives easier, in this exercise we're going to use text that's already been processed into a plain text format. We'll use the [Hugging Face library](https://huggingface.co/) which makes it easy to load data and models with only a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe1a37",
   "metadata": {},
   "source": [
    "After [installing the Hugging Face library](https://huggingface.co/docs/transformers/installation), we can call the following to load a dataset of PubMed articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f9197b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chrislovejoy/Library/miniconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No config specified, defaulting to: pubmed-summarization/section\n",
      "Found cached dataset pubmed-summarization (/Users/chrislovejoy/.cache/huggingface/datasets/ccdv___pubmed-summarization/section/1.0.0/f765ec606c790e8c5694b226814a13f1974ba4ea98280989edaffb152ded5e2b)\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 53.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"ccdv/pubmed-summarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eff39a7",
   "metadata": {},
   "source": [
    "This is a relatively small dataset but it's still 1.5GB and may take some time to load, depending on your computer and internet connection speed. In my case, it took just under 5 minutes. (Note: after the first time, your computer will cache it and won't need to re-download it the next time you come back to the exercise)\n",
    "\n",
    "You can browse other datasets accesible via Hugging Face [here](https://huggingface.co/datasets), and to load those you just need to change the parameter in the ```load_dataset()``` function call above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc34b23",
   "metadata": {},
   "source": [
    "Let's have a look at our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632ba1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'abstract'],\n",
       "        num_rows: 119924\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'abstract'],\n",
       "        num_rows: 6633\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'abstract'],\n",
       "        num_rows: 6658\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4945b758",
   "metadata": {},
   "source": [
    "We can see that it's divided into training, validation and test sets. This is because it's designed to be used for 'fine-tuning' NLP models. But we won't worry about that to begin with and will just use some of the data in the 'training' portion. We can view it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b8d48c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['article', 'abstract'],\n",
       "    num_rows: 119924\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9103273",
   "metadata": {},
   "source": [
    "But now we want to find the actually article texts. It's not *obvious* from just looking at the Dataset object we have exactly how to do that. \n",
    "\n",
    "This will be the case sometimes, and we have to figure out how to get to the data we want. There may be documentation on how to do so. But sometimes you'll need to experiment and figure it out.\n",
    "\n",
    "One helpful command for this is ```.__dict__```. Let's try that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b351b02e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset['train'].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a63a2ec",
   "metadata": {},
   "source": [
    "This may look like a bit of a jumble, but from within it we can see the structure of the dataset. To access the data, we first index to the datapoint of interest, and then we select either 'article' or 'abstract'. Let's look at the 10th article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61a82712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"an exponential rise in alzheimer 's disease ( ad ) prevalence rates is predicted to parallel the aging of baby boomers creating a potentially unsustainable economic burden to the healthcare system .   delaying the onset or progression of ad , even modestly , by earlier pharmacological intervention could substantially reduce the economic and psychosocial impact of the illness [ 1 , 2 ] .   unfortunately \\n , many ad patients remain undiagnosed or go undetected until the later stages of disease . \\n insights into the underlying pathological mechanisms involving beta - amyloid plaque deposition within the brain have   led to the development of a host of antiamyloid agents   that are in various stages of clinical investigation . \\n there is now a scientific consensus that the pathological events in ad initiate decades before clinical symptoms become apparent , and if disease modification is realized in the coming decades , the need for improved methods of early detection prior to the overt clinical signs will be accentuated .   traditionally , neuropsychological measures , particularly those that tap cognitive abilities subsumed by the hippocampal formation such as episodic memory , have shown usefulness in identifying cognitively normal elders who subsequently develop ad [ 4 , 5 ] . \\n decrements in semantic memory and concept formation have been shown to occur nearly a decade before the development of ad . \\n performance on visual - spatial and verbal memory measures in midlife have also been shown to predict later memory loss . \\n however , individuals with very high premorbid intellectual abilities experiencing incipient cognitive decline may go undetected , and false positives are possible in individuals with a low level of intellectual abilities . also appropriate \\n interpretation of extensive neuropsychological testing requires a high degree of expertise and training , which limits its use in routine clinical settings .   the advancement of molecular imaging tracers that bind to amyloid , such as pittsburgh compound b ( pib ) or longer - lived probes ( e.g. , fddnp ) , offers a non - invasive in vivo method to detect and quantify brain amyloid deposition [ 8 , 9 ] .   however , this approach for presymptomatic detection is economically impractical for routine use given the current costs and restrictions on  medically necessary  use . \\n similarly , biomarkers including a142 and phosphorylated tau ( also implicated in ad pathology ) in cerebral spinal fluid ( csf ) can predict subsequent cognitive decline [ 10 , 11 ] , but lumbar puncture carries risks and is inconvenient for wide - scale use in cognitively impaired elderly subjects . \\n blood - based biomarkers have more practical applicability for routine use and are likely to be more cost effective than both csf and imaging procedures .   consequently , measurement of a140 and a142 in blood is increasingly being explored and shows potential in identifying individuals at the preclinical stage of ad [ 1214 ] . \\n it has been reported that csf a levels are subject to high diurnal fluctuations with extremely high variability reported over 12 hours .   over days and weeks , \\n furthermore , serum contains more a than plasma , possibly due to the release of bound a during the clotting process . \\n hence , serum a appears suitable for use in predicting mci / ad and optimal sensitivity , and specificity is probably achievable if combined with current diagnostic procedures , such as brief neuropsychological testing .    in this study \\n , we examined the usefulness of brief neuropsychological tests in combination with blood a140 and a142 as a predictive test for detecting mci / ad in at - risk older adults at a pre - symptomatic stage . \\n such an approach will be more practical for clinical use and be germane in designing large - scale prevention trials . \\n participants included a subset of subjects enrolled in the alzheimer 's disease anti - inflammatory prevention trial ( adapt ) . \\n adapt was a randomized , placebo - controlled , multicenter primary prevention trial sponsored by the national institute on aging . \\n subjects were randomly assigned to one of three groups : celecoxib ( 200  mg b.i.d . ) , naproxen sodium ( 220  mg b.i.d . ) , or placebo . \\n full details of data collection , measurements , and study procedures are available at http://www.jhucct.com/adapt/manall43.pdf and described elsewhere . the inclusion criteria for adapt subjects were age of 70 or older at enrollment , a self - reported family history of ad - like dementia , and normal cognitive performance on a brief battery of neuropsychological tests . \\n recruitment for adapt began in 2002 , and the study was completed in 2007 . \\n in 2005 , the roskamp institute initiated a proteomic ancillary study ( f. crawford , pi ) involving blood draw from these subjects . \\n the inclusion criteria for this ancillary study stipulated that each subject was an active adapt participant and had met all the adapt inclusion and exclusion criteria . \\n a separate consent was also obtained from each subject who participated in the ancillary study . \\n two hundred and fifteen subjects from the roskamp adapt cohort enrolled in the proteomic ancillary study .   at the time of blood draw \\n , subjects maintained cognitively normal status as determined by their performance on an annual cognitive assessment battery . \\n blood was collected during the semi - annual followup visits , and the cognitive assessments were performed at the baseline visit and at the annual visits . \\n the time from baseline cognitive testing to the diagnosis of mci / ad was 4.06 years ( 1.3 sd ) . \\n timeframe from baseline cognitive testing to blood draw was 2.25 years ( 0.71  sd ) and from blood draw to diagnosis was 1.79 years ( 1.2 sd ) . \\n the cognitive measures completed at baseline and annual followup included the modified mini - mental state examination ( 3ms ) ; the hopkins verbal learning test - revised ( hvlt - r ) ; digit span ( forward and backward ) from the wechsler adult intelligence scale - revised ( wais - r ) ; a generative verbal fluency test ( supermarket items ) ; the narratives from the rivermead behavioral memory test ( rbmt ) ; the brief visuospatial memory test - revised ( bvmt - r ) . \\n the mini - mental state examination ( mmse )   was extracted from 3ms . \\n alternate forms were utilized annually for the hvlt - r , rbmt , and bvmt - r on each subsequent annual visit . \\n subjects also completed the 30-item geriatric depression scale   and a self - rating scale of memory functions . \\n collateral respondents completed the dementia severity rating scale ( dsrs ) .   due to significant intercorrelations between these tests , analyses described below \\n are limited to those baseline cognitive tests that were sensitive to early changes ( i.e. , verbal learning and memory ) associated with mci / ad   or tests that were similar to those previously shown to be associated with a levels .   normative data from the cache county study was used to develop the standardized cut - off scores utilized in adapt . \\n individuals who scored below the cut scores on annual cognitive assessments underwent further dementia workup including physical and neurological examinations , laboratory studies ( i.e. , cbc , chemistry count , sedimentation rate , vitamin b12 and folic acid levels , thyroid test , and syphilis serological test ) , and neuroimaging ( i.e. , mri or ct ) , as applicable . \\n a more comprehensive neuropsychological assessment was also administered by a neuropsychologist as part of the dementia work - up . \\n this battery of tests consisted of the expanded consortium to establish a registry for alzheimer 's disease ( cerad ) battery ; logical memory i and ii of the wechsler memory scale - revised ; benton visual retention test   ( benton ) ; a generative fluency test ( animals ) ; control oral word association test ( cowat ; cfl ) ; the trail making test ; symbol digit modalities test ( smdt ) ; shipley vocabulary . \\n following completion of all components of the dementia work - up , a consensus team determined cognitive status using published diagnostic criteria . \\n the diagnosis of ad was made using nincds - adrda   and amnestic mild cognitive impairment ( mci ) using petersen criteria . \\n all mci patients were considered to be amnestic mci , as they only had memory impairment , but maintained normal activities of daily living and overall had a well - preserved cognition in other cognitive domains . \\n ample evidence indicates that amnestic mci patients may be in a transitional stage between normal aging and ad with 85% of these subjects converting to ad over a 7-year period . \\n additional evidence comes from an imaging study which demonstrated that the pattern of brain atrophy in amnestic mci patients is typical of that observed in ad patients . \\n it is then reasonable to combine these diagnoses in a single category , thus allowing a large enough numbers to supply statistical power . of the 215 subjects who gave blood for the ancillary study , two developed non - ad dementia , and \\n of the remaining subject pool of 208 used in these analyses , 28 subjects met criteria for either ad ( n = 10 ) or mci ( n = 18 ) in the two years following blood draw . \\n the serum a content was determined , as per manufacturer 's instructions , using the elisa kits for human a140 and a142 and the inter - assay cv , and the intraassay cv was reported to be 10% ( invitrogen , calif ) . \\n dna was extracted from whole blood for apoe genotyping using pure gene kits ( gentra systems , calif ) , and apoe genotyping was performed using previously established methods , as described elsewhere . \\n apoe genotypes were unavailable for 4 individuals , but these were included in the analyses . \\n the data set was range checked , and prior to analyses , the dependent and independent variables were examined for missing data , outliers , and violations of the normalcy assumption . \\n differences among groups on demographic variables , neuropsychological variables , and serum a140 levels were examined using either the student 's t - test or  analyses , depending on the type of variable measurement . \\n time - updated cox regression modeling was used to test whether neuropsychological test scores , a , or a combination of both can predict conversion to mci / ad in individuals who were cognitively normal at baseline . \\n potential confounding variables shown to impact risk for cognitive decline included age , education , gender , apoe status , serum creatinine , triglycerides , presence of apoe 4 allele , and history of vascular disease as determined by treatment with statins or antihypertensive medication which were entered as covariates .   the latter variables , coded dichotomously , have been previously shown to impact a levels . \\n because previous analyses revealed a nonsignificant increase of ad risk with naproxen in this cohort , we also controlled for this effect . \\n logistic regression modeling was employed to construct receiver operator curves ( roc ) to examine the predictive performance of neuropsychological measures from the baseline visit and serum a levels in diagnoses of mci / ad . \\n roc curve comparisons were based on area under the curve ( auc ) , se , and the associated 95% confidence interval ( ci ) . \\n we subsequently calculated sensitivity of the various models using the predicted probability of each subject by logistic regression modeling with specificity of at least eighty percent . \\n post hoc power calculations using the g - power software for multivariate regression analyses utilized here suggest a power of nearly 100% at the alpha value 0.05 for the current sample size , total number of predictors , and the observed effect size . \\n the mean age and education of the sample was 76.7 ( sd = 3.9 ) and 14.6 ( sd = 2.8 ) years , respectively . \\n the majority of the sample was caucasian ( 98.1% ) , and 51.9% were male . despite the cohort 's self - report of enriched family history , less than one - third of the total sample ( 31.7% ) carried at least one apoe 4 allele , a frequency similar to the general population . \\n comparisons on variables between subjects who remained cognitively normal and those who declined over the short follow - up period are reported in table 1 . \\n although all subjects at enrollment performed within the normal limits based on the established cut - off scores , those that ultimately declined had generally poorer scores on the 3ms , mmse , and all memory measures . \\n the two groups were also significantly different on serum a142 levels and a142/a140 ratios prior to diagnoses of mci / ad . \\n only 23% of the cognitively normal individuals had serum a142 in the lowest quartile compared to the nearly 50% of the diagnostic group ( 44% of mci subjects and 50% of ad subjects ) . \\n time - dependent cox regression analyses were performed to examine the relationship between these cognitive tests and a on the prediction of subsequent conversion to mci / ad . \\n all neuropsychological analyses were adjusted for age , gender , and education , but no adjustment for the study medications was required as these were baseline scores . \\n cox regression analyses show that the model using neuropsychological tests predicted mci / ad ( 2 log - likelihood = 206.51 ,  = 52.11 , df = 8 , p < .001 ) . \\n significant individual neuropsychological measures were 3ms (  = 0.25  0.06 , wald = 17.78 , p < .001 ) ; generative verbal fluency (  = 0.12  0.04 , wald = 8.09 , p < \\n .004 ) ; hvlt - r scores (  = 0.24  0.11 , wald = 4.58 p < .032 ) . \\n cox regression analysis showed that a142 measured in the lowest two quartiles compared to the highest quartile was a significant individual predictor of conversion to mci / ad in this model ( 2 log - likelihood = 197.47 ,  = 38.41 , df = 15 , p < .001 ) . \\n the regression analysis utilizing the a142/a140 ratio found similarly significant results ( 2 log - likelihood = 204.69 ,  = 36.10 , df = 14 , p < .001 ) with the lowest ratios being most predictive of subsequent conversion to mci / ad . the final full model , adjusting for confound and the study medications , included hvlt - r , fluency , 3ms , a142 levels , and a142 quartiles ( 2 log - likelihood = 166.25 ,  = 74.55 , df = 18 , p < .001 ) with fluency , 3ms , and a142 in the lowest two quartiles as significant individual predictors of mci / ad in the model . \\n similar results were observed when a140 levels and a142 quartiles were substituted in this model with a142/a140 ratios ( 2 log - likelihood = 168.49 ,  = 72.90 , df = 17 , p < .001 ) . \\n baseline values for the 3ms , hvlt - r , and generative verbal fluency scores were subtracted from those obtained at the 12-month repeat testing to determine if changes in these measures differ by a142 and a142/a140 ratios . in unadjusted analyses , among subjects who converted to mci / ad , the greatest decline for hvlt - r was observed among individuals with the lowest quartile of a142 ( 1.17 ,   2.33  sd ) and a142/a140 ratios ( 0.75 , 2.63  sd ) where individuals in the highest quartile of a142 ( 1.33 ,   1.86  sd ) and a142/a140 ratios improved by nearly one point ( 0.6  1.82 sd ) . \\n however , these differences were not statistically significant ( p > .05 ) .    for the 3ms scores , among subjects who converted to mci / ad , those with a142 in the lowest quartile declined ( 1.83  1.28  sd ) as compared to the highest quartile ( 4.83  1.35  sd ) , and this difference was statistically significant ( f = 3.42 ,  p = .033 ) .   for mci / ad subjects with the lowest quartile of the a142/a140 ratios , the 3ms values remained ultimately unchanged ( 0.16  1.20  sd ) , \\n while the scores improved among those with the highest quartile of the a142/a140 ratios ( 4.33  1.20  sd ) , and these differences were also statistically significant ( f = 3.10 , p = .046 ) .   for generative verbal fluency test , a decline was noted in both the lowest quartile ( 4.17  1.40  sd ) and the highest quartile ( 1.17  2.13  sd ) of a142 , and these differences were marginally significant ( f = 2.63 , p = .073 ) .   for a142/a140 ratios , \\n a similar pattern was observed , but this difference was not statistically significant .   among individuals who remained cognitively normal , \\n while a similar pattern was observed , those with lowest quartile of a142 and a142/a140 ratios had a larger decline than those with the highest quartile for each hvlt - r ( 0.28  0.27  sd versus . \\n 0.14  0.33  sd , respectively . ) and 3ms ( 1.02  0.51  sd versus 0.39  0.44  sd ) . \\n however , due to the small magnitude of the change in these scores , these differences were not statistically significant . \\n no such change was observed for the generative verbal fluency test ( data not shown ) . \\n examination of sensitivity and specificity using roc analysis revealed the auc for neuropsychological testing with age , education , and gender as covariates was 0.83 ( 95% ci [ 0.750.91 ] , p < .001 ) .   for a142 \\n ( adjusted for presence of apoe 4 allele , vascular risk factors , and associated medications ) , the auc was 0.79 ( 95% ci [ 0.700.88 ] , p < .001 ) .   when neuropsychological testing ( 3ms , hvlt - r , and generative verbal fluency ) and a142 were combined , the auc was increased to 0.91 ( 95% ci [ 0.860.95 ] , p < .001 ) .   for the adjusted ( as above ) a142/a140 ratios alone , \\n .001 ) , and when combined with the neuropsychological measures , auc was 0.91 ( 95%ci [ 0.870.96 ] , p < .001 ) . \\n optimal sensitivities with specificity of at least 80% predicted probabilities are shown in table 2 .   the highest sensitivity and specificity \\n was achieved using a combination of cognitive scores and a142/a140 ratio , but this finding was driven by a142 . \\n the pathogenesis of ad is initiated before the clinical symptoms of cognitive impairment and functional decline become apparent in its victims . \\n a simple and pragmatic method for identifying older adults at an increased risk for mci / ad who may benefit from targeted prevention is therefore of importance in reducing the burden of ad . \\n the combination of brief neuropsychological tests along with blood - based biomarkers of ad represents a reasonable approach with a potential for wide - scale use . \\n our findings here provide support for this notion and demonstrate that early prediction of risk for developing mci / ad may be feasible via a combination of brief neuropsychological tests and biomarkers in an at - risk cohort . in this subcohort from adapt , measures of global cognitive function ( 3ms ) , episodic memory ( hvlt - r trial 4 ) , language fluency , and serum a142/a140 ratio achieved an excellent accuracy of 91% . furthermore , sensitivity with specificity of at least 80% for the combined measures was superior to neuropsychological measures or to serum a levels alone . \\n we have recently shown that a levels alone can predict mci / ad , but a levels are influenced by vascular disease and associated medications   and require adjustment to observe the full impact of a in predictive modeling . \\n we have also shown that in subjects diagnosed with ad , there is an association between measures of language tests of fluency and object naming and a140 and that memory performance is associated with serum a142    . \\n an association between serum a140 and cognitive measures of memory and language has also been reported in cognitively normal older adults . \\n high baseline a142 and a140 with stable a142 over time is shown to be associated with diminishing cognition . \\n more recently , yaffe and colleagues demonstrated that low a142/a140 ratios predict cognitive decline over 9 years . in our study , we demonstrate that low a142 and a142/a140 ratios are associated with cognitive decline even within one year . \\n this is extremely valuable from the clinical perspective , as the ability to identify at - risk individuals within a year prior to the onset can significantly improve the quality of care and the recruitment strategy for prevention trials by redirecting those individuals who may not benefit from preventive therapies towards more suitable clinical intervention . \\n this is demonstrated by recent adapt findings , which suggest that individuals with low baseline cognitive scores converted soon after the trial initiated and that neither naproxen nor celecoxib intervention was beneficial to these individuals . \\n collectively , these findings suggest that combining cognitive tests with blood a may be useful for predicting future mci / ad , which to date has not been explored , particularly as either a or the cognitive tests alone may not have the desired sensitivity or specificity for prediction of future mci / ad . \\n this current work presented here provides evidence that the combination of brief neuropsychological tests and blood a has potential utility in predicting mci / ad at least 2 to 4 years prior to the clinical classification of mci or diagnosis of ad . \\n in addition , our findings also demonstrate the importance of accounting for factors such as apoe , vascular risk factors , and medications when using a in predicting mci / ad . \\n although at present no studies have reported sensitivity and specificity of csf a142 in predicting mci / ad conversion from normal cognition , a large multicenter study has shown that csf a142 predicts transition from mci to ad , while tau alone achieved a high sensitivity ( 83% ) with acceptable specificity ( 72% ) . \\n it is interesting to note that our findings using blood and cognitive tests , a far less invasive method , resulted in higher sensitivities and specificities for predicting cognitive decline in at - risk cognitively normal older adults . despite the limitation that blood sampling was not conducted at the same time point as the cognitive testing , \\n our data provide strong support for further evaluation of this approach , particularly as we have not seen significant fluctuations in a levels over a one - year period ( pers . \\n our study provides support that blood - based a levels may have diagnostic utility when combined with neuropsychological measures .   this proposed method warrants further investigation to determine its practical applicability in specialized clinic setting by allied health personal and in routine primary care clinics .\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][10]['article']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06f88d0",
   "metadata": {},
   "source": [
    "Great! It looks like an article about Alzheimer's Disease and blood-based markers for diagnosis. Now that we can access the full articles, let's preparing our data for our large language model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f013cbd",
   "metadata": {},
   "source": [
    "## Step 2: Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcc926e",
   "metadata": {},
   "source": [
    "Let's keep going with our Alzheimer's Disease article to help us understand the data.\n",
    "\n",
    "If we look at the text above, we can notice that there are a lot of extra spaces and certain symbols that we don't normally have like '\\n'. This reflects the fact that text is divided into 'tokens' for the purpose of performing NLP.\n",
    "\n",
    "Tokens are a set of characters that represents a \"unit of meaning\" in a text. Tokens are typically individual words, but they can also be phrases or other meaningful sequences of characters, such as numbers, symbols, or punctuation marks.\n",
    "\n",
    "If we were working with a new dataset, we might need to be tokenisation ourselves. In this case, it's already done for us.\n",
    "\n",
    "Each token is separated by a space. The '\\n' token denotes a new line.\n",
    "\n",
    "If we use the Python ```print()``` function, it will convert the '\\n' symbols into new lines, which make it easier to follow. However, the additional spacing will still be present.\n",
    "\n",
    "*(NOTE: we'll index the text to only look at the first 5000 characters, rather than print out the entire article below)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3831df91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an exponential rise in alzheimer 's disease ( ad ) prevalence rates is predicted to parallel the aging of baby boomers creating a potentially unsustainable economic burden to the healthcare system .   delaying the onset or progression of ad , even modestly , by earlier pharmacological intervention could substantially reduce the economic and psychosocial impact of the illness [ 1 , 2 ] .   unfortunately \n",
      " , many ad patients remain undiagnosed or go undetected until the later stages of disease . \n",
      " insights into the underlying pathological mechanisms involving beta - amyloid plaque deposition within the brain have   led to the development of a host of antiamyloid agents   that are in various stages of clinical investigation . \n",
      " there is now a scientific consensus that the pathological events in ad initiate decades before clinical symptoms become apparent , and if disease modification is realized in the coming decades , the need for improved methods of early detection prior to the overt clinical signs will be accentuated .   traditionally , neuropsychological measures , particularly those that tap cognitive abilities subsumed by the hippocampal formation such as episodic memory , have shown usefulness in identifying cognitively normal elders who subsequently develop ad [ 4 , 5 ] . \n",
      " decrements in semantic memory and concept formation have been shown to occur nearly a decade before the development of ad . \n",
      " performance on visual - spatial and verbal memory measures in midlife have also been shown to predict later memory loss . \n",
      " however , individuals with very high premorbid intellectual abilities experiencing incipient cognitive decline may go undetected , and false positives are possible in individuals with a low level of intellectual abilities . also appropriate \n",
      " interpretation of extensive neuropsychological testing requires a high degree of expertise and training , which limits its use in routine clinical settings .   the advancement of molecular imaging tracers that bind to amyloid , such as pittsburgh compound b ( pib ) or longer - lived probes ( e.g. , fddnp ) , offers a non - invasive in vivo method to detect and quantify brain amyloid deposition [ 8 , 9 ] .   however , this approach for presymptomatic detection is economically impractical for routine use given the current costs and restrictions on  medically necessary  use . \n",
      " similarly , biomarkers including a142 and phosphorylated tau ( also implicated in ad pathology ) in cerebral spinal fluid ( csf ) can predict subsequent cognitive decline [ 10 , 11 ] , but lumbar puncture carries risks and is inconvenient for wide - scale use in cognitively impaired elderly subjects . \n",
      " blood - based biomarkers have more practical applicability for routine use and are likely to be more cost effective than both csf and imaging procedures .   consequently , measurement of a140 and a142 in blood is increasingly being explored and shows potential in identifying individuals at the preclinical stage of ad [ 1214 ] . \n",
      " it has been reported that csf a levels are subject to high diurnal fluctuations with extremely high variability reported over 12 hours .   over days and weeks , \n",
      " furthermore , serum contains more a than plasma , possibly due to the release of bound a during the clotting process . \n",
      " hence , serum a appears suitable for use in predicting mci / ad and optimal sensitivity , and specificity is probably achievable if combined with current diagnostic procedures , such as brief neuropsychological testing .    in this study \n",
      " , we examined the usefulness of brief neuropsychological tests in combination with blood a140 and a142 as a predictive test for detecting mci / ad in at - risk older adults at a pre - symptomatic stage . \n",
      " such an approach will be more practical for clinical use and be germane in designing large - scale prevention trials . \n",
      " participants included a subset of subjects enrolled in the alzheimer 's disease anti - inflammatory prevention trial ( adapt ) . \n",
      " adapt was a randomized , placebo - controlled , multicenter primary prevention trial sponsored by the national institute on aging . \n",
      " subjects were randomly assigned to one of three groups : celecoxib ( 200  mg b.i.d . ) , naproxen sodium ( 220  mg b.i.d . ) , or placebo . \n",
      " full details of data collection , measurements , and study procedures are available at http://www.jhucct.com/adapt/manall43.pdf and described elsewhere . the inclusion criteria for adapt subjects were age of 70 or older at enrollment , a self - reported family history of ad - like dementia , and normal cognitive performance on a brief battery of neuropsychological tests . \n",
      " recruitment for adapt began in 2002 , and the study was completed in 2007 . \n",
      " in 2005 , the roskamp institute initiated a proteomic ancillary study ( f. crawford , pi ) involving blood draw from these subjects . \n",
      " the inclusion criteria for this ancillary study stipulated that each subject was an active adapt participant and had met all the adapt incl\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][10]['article'][:5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24919274",
   "metadata": {},
   "source": [
    "We're going to be feeding this text data into our language models. However, an important consideration here is the length of our text. Language models have limits on the length of text that they can take in at one point in time. \n",
    "\n",
    "For example, GPT-derived models can typically take a maximum 1024-2048 tokens. This needs to include *both* the text that we're providing it as well as the accompanying command that we're going to provide.\n",
    "\n",
    "We can look at the number of characters using ```len()```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a05ce398",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22397"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train'][10]['article'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d2cb31",
   "metadata": {},
   "source": [
    "However, there's not a direct conversion of characters to 'tokens', given that the token length can vary.\n",
    "\n",
    "We can use the handy NLTK library for this. NLTK is the 'natural language toolkit' and contains a range of helpful functions including tokenisation, text tagging and more.\n",
    "\n",
    "Let's import it and use the ```word_tokenize()``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a167ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3936\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(len(nltk.word_tokenize(dataset['train'][10]['article'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803d077e",
   "metadata": {},
   "source": [
    "Nearly 4000 tokens... That's going to be a problem as it's quite a way above our limit.\n",
    "\n",
    "**What can we do?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a5822b",
   "metadata": {},
   "source": [
    "There's a few different approaches and the most appropriate approach depends on our end goal.\n",
    "\n",
    "One option is to use a tool like [GPT Index](https://gpt-index.readthedocs.io/en/latest/index.html). This tool divides the text into parts, which it calls \"indices\". Then, when you ask a question, it will identify which of the indices (ie. which segments of the original text) are the best for answering that particular question, and it will use that section to generate an answer.\n",
    "\n",
    "An alternative is to create a *summary* of the original text, and then use that summary as the basis for future questions to the language model.\n",
    "\n",
    "The GPT Index approach is necessary if the text is very long. If there were 10,000+ tokens in the original text, for example, it wouldn't be possible to make a summary without losing key information.\n",
    "\n",
    "In our case, we need to condense to around 20-25% (from ~4000 tokens to ~1000 tokens), which is quite reasonable. Therefore, we'll go with summarisation - and this is also easier to implement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f24624",
   "metadata": {},
   "source": [
    "## Part 3: Using AI to create an initial summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69c1b41",
   "metadata": {},
   "source": [
    "### Extractive and Abstractive summarisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3f7e32",
   "metadata": {},
   "source": [
    "There are broadly two types of summarisation: **extractive** and **abstractive** summarisation.\n",
    "\n",
    "In **extractive** summarisation, the model highlights the most important sentences in the text and cuts out all the rest. So the final summary has no *new* words and is made of all the important sentences put together.\n",
    "\n",
    "In **abstractive** summarisation, the model *creates* a new summary in its own words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e067b67",
   "metadata": {},
   "source": [
    "In this exercise, we're going to use **abstractive** summarisation. \n",
    "\n",
    "Given the token limitations, we can't just ask the model to write an overall summary. So let's divide it up into chunks, create a short summary of each chunk, and then combine the chunks to make the overall summary. The result won't be *perfect*, but hopefully it contains all the information we will need. Let's use the **textwrap3** library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06fee59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9161ebd",
   "metadata": {},
   "source": [
    "We can write a function that splits up our article into separate 'chunks':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ecdf8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_length = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "517b9603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_paper(paper):    \n",
    "    chunks = textwrap3.wrap(paper, chunk_length)    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5792db56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paper = dataset['train'][10]['article']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec64379",
   "metadata": {},
   "source": [
    "Let's look at first first 'chunk' as a sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88952443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"an exponential rise in alzheimer 's disease ( ad ) prevalence rates is predicted to parallel the aging of baby boomers creating a potentially unsustainable economic burden to the healthcare system .   delaying the onset or progression of ad , even modestly , by earlier pharmacological intervention could substantially reduce the economic and psychosocial impact of the illness [ 1 , 2 ] .   unfortunately   , many ad patients remain undiagnosed or go undetected until the later stages of disease .   insights into the underlying pathological mechanisms involving beta - amyloid plaque deposition within the brain have   led to the development of a host of antiamyloid agents   that are in various stages of clinical investigation .   there is now a scientific consensus that the pathological events in ad initiate decades before clinical symptoms become apparent , and if disease modification is realized in the coming decades , the need for improved methods of early detection prior to the overt clinical signs will be accentuated .   traditionally , neuropsychological measures , particularly those that tap cognitive abilities subsumed by the hippocampal formation such as episodic memory , have shown usefulness in identifying cognitively normal elders who subsequently develop ad [ 4 , 5 ] .   decrements in semantic memory and concept formation have been shown to occur nearly a decade before the development of ad .   performance on visual - spatial and verbal memory measures in midlife have also been shown to predict later memory loss .   however , individuals with very high premorbid intellectual abilities experiencing incipient cognitive decline may go undetected , and false positives are possible in individuals with a low level of intellectual abilities . also appropriate   interpretation of extensive neuropsychological testing requires a high degree of expertise and training , which limits its use in routine clinical settings .   the advancement of molecular imaging tracers\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_paper(test_paper)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8a6be5",
   "metadata": {},
   "source": [
    "### Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf9a70d",
   "metadata": {},
   "source": [
    "For each of those chunks, we now want GPT to generate a summary.\n",
    "\n",
    "So **how do we do that?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62fa1f2",
   "metadata": {},
   "source": [
    "The way that GPT-3 and similar models work is that you **ask them in 'natural language'** (ie. using words). If you want to understand who is mentioned in a text, you could say something like \"Read this text and list all the people it contains\". If you want to translate a text into another language, you could say \"Re-write this paragraph into French\".\n",
    "\n",
    "This is great, because it means the same model can perform many different types of task. Before GPT, you would often use models that specifically performed one thing.\n",
    "\n",
    "However, writing the \"prompts\" that give the response you want is something of an art. The model's responses can vary a lot depending on small changes in the instructions. (You can read more about this [here](https://gwern.net/gpt-3#prompts-as-programming).)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b987b27d",
   "metadata": {},
   "source": [
    "Here's a simple prompt that works quite well for our purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad9b5048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(chunk):\n",
    "    prompt = f\"Write a concise summary of the following: \\n \\n {chunk} \\n \\n CONCISE SUMMARY:\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e60f5",
   "metadata": {},
   "source": [
    "Have a go at playing around with your own prompts and comparing how the outputs of the model vary.\n",
    "\n",
    "You can do that within this Jupyter Notebook, plus OpenAI have a \"playground\" to experiment in: https://platform.openai.com/playground\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801af7ba",
   "metadata": {},
   "source": [
    "### Using the GPT API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0d82c7",
   "metadata": {},
   "source": [
    "No we're going to interact with our model. One option would be to load a model into our Jupyter Notebook and interact with it. An easier option, though, is to send our text to a language model 'API'.\n",
    "\n",
    "An 'API' is an \"Application Programming Interface\", which basically means it's somewhere that you can send information and receive information back.\n",
    "\n",
    "OpenAI have an API for the GPT models, so we can send our text their, directly from within this notebook. To do that, we'll import the openai library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d119bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad55dcf",
   "metadata": {},
   "source": [
    "And we'll need to define our 'API key'. This is a long string of text which tells the OpenAI API *who* is sending the request. To get this, you'll need to make an account with OpenAI and generate a new API key, which you can copy into the cell below.\n",
    "\n",
    "One reason for the API key is to stop people attacking their service with too many requests. But another reason is that this service isn't *free*, and so they use the API key to know which account to charge.\n",
    "\n",
    "It's not *free*, but the cost for personal use is very low. A whole day of playing with the model and sending requests will cost less than a coffee. I'd say it's worth it for the educational experience.\n",
    "\n",
    "But if you're absolutely against spending money here, an alternative is to load a model from [Hugging Face](https://huggingface.co) and using it in the notebook - see the documentation on their website for how to do so (it's a fair amount more work than calling OpenAI's API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1adb526",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d693ed3",
   "metadata": {},
   "source": [
    "To send the API request, there are a number of standard variables we need to provide. Have a look at the [OpenAI API documentation](https://platform.openai.com/docs/api-reference/completions) and fill out the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cd56fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_completion(chunk):\n",
    "    result = openai.Completion.create(\n",
    "    model=\"\", # TODO: add model name here\n",
    "    prompt=generate_prompt(chunk),\n",
    "    max_tokens = 1000,\n",
    "    temperature = , # TODO: add an appropriate temperature here\n",
    "    n = 1\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4862c9bb",
   "metadata": {},
   "source": [
    "### Bringing it together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e33005",
   "metadata": {},
   "source": [
    "We now have functions for (1) dividing our long text into chunks, (2) generating a prompt to summarise the chunk and (3) asking OpenAI's GPT to perform that task.\n",
    "\n",
    "The final step is to run all of those functions over our full text to generate our summary.\n",
    "\n",
    "Fill out the gaps in the cell below to generate a summary for the Alzheimer's paper we've been looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22861206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary(paper):\n",
    "    chunks = # TODO: use the relevant function to create the chunks\n",
    "    results = []\n",
    "    for chunk in chunks:\n",
    "        result = gpt_completion() # TODO: add the relevant argument here for the gpt_completion function call\n",
    "        chunk_summary = # TODO: look at what 'result' includes and index into the appropriate text we want\n",
    "        results.append(chunk_summary)\n",
    "    summary = ' '.join(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "382b8bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "alzheimers_paper = dataset['train'][10]['article']\n",
    "\n",
    "summary = create_summary(alzheimers_paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e131ac",
   "metadata": {},
   "source": [
    "### Looking at our summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b817d08",
   "metadata": {},
   "source": [
    "We can look at the summary that our model created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7936d3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The prevalence of Alzheimer's Disease (AD) is expected to increase as the Baby Boomer generation ages, creating a potentially unsustainable economic burden on the healthcare system. To reduce this burden, antiamyloid agents are being developed to delay the onset or progression of AD. Neuropsychological measures have been used to identify cognitively normal elders who subsequently develop AD, but false positives are possible and interpretation of extensive testing requires expertise. Molecular imaging tracers are being developed to improve early detection.  This study examined the usefulness of brief neuropsychological tests in combination with blood Aβ140 and Aβ142 as a predictive test for detecting MCI/AD in at-risk older adults at a pre-symptomatic stage. This approach is more practical for clinical use and could be used to design large-scale prevention trials. Participants included a subset of subjects enrolled in the Alzheimer's Disease Anti-Inflammatory Prevention Trial (ADAPT).  Adapt was a randomized, placebo-controlled, multicenter primary prevention trial sponsored by the National Institute on Aging. Subjects aged 70 or older with a family history of AD-like dementia and normal cognitive performance were randomly assigned to one of three groups: celecoxib, naproxen sodium, or placebo. An ancillary study involving blood draw from these subjects was initiated in 2005, and 215 subjects enrolled. Cognitive assessments were performed at baseline and annual followup visits, and the time from baseline cognitive testing to diagnosis of MCI/AD was 4.06 years. Blood was collected during semi-annual followup visits, and the timeframe from baseline cognitive testing to blood draw was 2.25 years and from blood draw to diagnosis was 1.79 years.  This study utilized a battery of cognitive tests to assess early changes associated with mild cognitive impairment (MCI) or Alzheimer's Disease (AD). Tests included the Wechsler Adult Intelligence Scale-Revised (WAIS-R) Digit Span (forward and backward), a generative verbal fluency test (supermarket items), the Rivermead Behavioral Memory Test (RBMT) narratives, the Brief Visuospatial Memory Test-Revised (BVMT-R), the Mini-Mental State Examination (MMSE), the 30-item Geriatric Depression Scale, and the Dementia Severity Rating Scale (DSRS). Further dementia workup included physical and neurological examinations, laboratory studies, and neuroimaging. A more comprehensive neuropsychological assessment was also administered by a neuropsychologist.  A consensus team used published diagnostic criteria to determine cognitive status of 215 subjects who had completed a dementia work-up. Of these, 28 met criteria for either Alzheimer's Disease (AD) or Amnestic Mild Cognitive Impairment (MCI). Serum A content and APOE genotyping were used to analyze the data set. The results showed that 85% of MCI patients converted to AD over a 7-year period, and imaging studies demonstrated that the pattern of brain atrophy in MCI patients was similar to that of AD patients.  This study examined differences among groups on demographic variables, neuropsychological variables, and serum A140 levels using either the Student's t-test or analyses. Time-updated Cox regression modeling was used to test whether neuropsychological test scores, A140 levels, or a combination of both can predict conversion to MCI/AD in individuals who were cognitively normal at baseline. Logistic regression modeling was employed to construct receiver operator curves (ROC) to examine the predictive performance of neuropsychological measures and serum A140 levels. The sample had a mean age of 76.7 and mean education of 14.6, and was 98.1% Caucasian. Post hoc power calculations suggest a power of nearly 100% at the alpha value 0.05.  In a cohort of individuals with a self-reported enriched family history, 51.9% were male and 31.7% carried at least one APOE4 allele, similar to the general population. Those who declined cognitively had poorer scores on neuropsychological tests and lower serum A142 levels and A142/A140 ratios. Cox regression analyses showed that the model using neuropsychological tests and A142 levels predicted MCI/AD, with significant individual predictors being 3MS, generative verbal fluency, and HVLT-R scores.  This study found that the lowest quartiles of a142 and a142/a140 ratios were most predictive of conversion to MCI/AD. The final full model included HVLT-R, fluency, 3MS, a142 levels, and a142 quartiles. Changes in HVLT-R and 3MS scores were significantly different between the lowest and highest quartiles of a142 and a142/a140 ratios, with the lowest quartiles showing the greatest decline.  A decline in both the lowest and highest quartiles of a142 was observed, and these differences were marginally significant. Neuropsychological testing combined with a142 and a142/a140 ratios had the highest sensitivity and specificity in predicting probabilities of Alzheimer's Disease, with an AUC of 0.91. This finding was driven by a142.  This study provides evidence that a combination of brief neuropsychological tests and biomarkers can accurately predict risk of developing Mild Cognitive Impairment or Alzheimer's Disease in an at-risk cohort. The combination of tests and biomarkers achieved an accuracy of 91%, with a sensitivity and specificity of at least 80%. Low levels of serum A142 and A142/A140 ratios were associated with cognitive decline even within one year, making this approach valuable from a clinical perspective.  Recent findings suggest that combining cognitive tests with blood biomarkers may be useful for predicting future MCI/AD at least 2-4 years prior to diagnosis. This study found that the combination of brief neuropsychological tests and blood biomarkers had higher sensitivities and specificities for predicting cognitive decline in at-risk cognitively normal older adults than either test alone. Further evaluation of this method is needed.  This study suggests that combining blood-based A levels with neuropsychological measures may be useful in diagnosing certain conditions. Further research is needed to determine the practical applicability of this approach in specialized clinics and primary care settings.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fa9abc",
   "metadata": {},
   "source": [
    "Let's compare it's length with the original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81260d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original text was 22397 characters.\n",
      "The summary text is 6234 characters.\n",
      "\n",
      "This is 27.83 percent of the original length.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The original text was {len(alzheimers_paper)} characters.\")\n",
    "print(f\"The summary text is {len(summary)} characters.\")\n",
    "\n",
    "import numpy as np\n",
    "print(f\"\\nThis is {np.round(len(summary)/len(alzheimers_paper) * 100,2)} percent of the original length.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eff6c28",
   "metadata": {},
   "source": [
    "That's a pretty decent compression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3056e349",
   "metadata": {},
   "source": [
    "We should also do a visual inspection of the summary text. Does it seem like a reasonable representation?\n",
    "\n",
    "This is one of the challenges with with NLP: numerical, objective measures of performance can be harder, because text is so varied. So it's always worth visually inspecting the text ourselves and seeing if it looks reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c933b3e",
   "metadata": {},
   "source": [
    "If our text is still too long, one option is to do a second round of summarisation. We could also experiment with changing the prompt. We asked for a \"concise summary\", but could change it - for example, to \"very concise summary\", or specify a maximum number of sentences, etc. It's ultimately about trial-and-error, to see what gives the desired output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffec7d00",
   "metadata": {},
   "source": [
    "## Part 4: Using our summary to answer questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc97f2",
   "metadata": {},
   "source": [
    "Now that we've generated an initial summary, we can use it to answer questions about the text and to generate other forms of summaries. For example, we could generate an Abstract using a set format (Background, Methods, Results, Conclusion) and compare this to the *true* abstract of the paper.\n",
    "\n",
    "To do this, we can continue to use GPT - and just create new prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31703a2",
   "metadata": {},
   "source": [
    "Let's first define a general function which can take in both our summary and our prompt function, and return the generated text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7609174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_complete_custom_prompt(summary, prompt_function):\n",
    "    result = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=prompt_function(summary),\n",
    "    max_tokens = 1000,\n",
    "    temperature = 0.25,\n",
    "    n = 1\n",
    "    )\n",
    "    return result['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af53bcea",
   "metadata": {},
   "source": [
    "### Creating an abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a8f77",
   "metadata": {},
   "source": [
    "Here is an example prompt for creating an abstract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c528d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for creating full abstract\n",
    "def make_abstract_prompt(summary):\n",
    "    prompt = f\"I want you to act as an academic researcher writing an abstract for an academic article you wrote.\\\n",
    "    I will share a summary of the article and it will be your job to write the abstract. The abstract should have four sections: \\\n",
    "    background, materials and methods, results and conclusion. PAPER: \\n \\ ${summary} \\n \\ ABSTRACT: \\n BACKGROUND:\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdc9a8b",
   "metadata": {},
   "source": [
    "Let's test it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d65f6c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"BACKGROUND:  The prevalence of Alzheimer's Disease (AD) is expected to increase as the Baby Boomer generation ages, creating a potentially unsustainable economic burden on the healthcare system. To reduce this burden, antiamyloid agents are being developed to delay the onset or progression of AD. Neuropsychological measures have been used to identify cognitively normal elders who subsequently develop AD, but false positives are possible and interpretation of extensive testing requires expertise. Molecular imaging tracers are being developed to improve early detection. \\n\\nMATERIALS AND METHODS: This study utilized a battery of cognitive tests to assess early changes associated with mild cognitive impairment (MCI) or Alzheimer's Disease (AD). Tests included the Wechsler Adult Intelligence Scale-Revised (WAIS-R) Digit Span (forward and backward), a generative verbal fluency test (supermarket items), the Rivermead Behavioral Memory Test (RBMT) narratives, the Brief Visuospatial Memory Test-Revised (BVMT-R), the Mini-Mental State Examination (MMSE), the 30-item Geriatric Depression Scale, and the Dementia Severity Rating Scale (DSRS). Further dementia workup included physical and neurological examinations, laboratory studies, and neuroimaging. A more comprehensive neuropsychological assessment was also administered by a neuropsychologist. A consensus team used published diagnostic criteria to determine cognitive status of 215 subjects who had completed a dementia work-up. Of these, 28 met criteria for either Alzheimer's Disease (AD) or Amnestic Mild Cognitive Impairment (MCI). Serum A content and APOE genotyping were used to analyze the data set. \\n\\nRESULTS: The results showed that 85% of MCI patients converted to AD over a 7-year period, and imaging studies demonstrated that the pattern of brain atrophy in MCI patients was similar to that of AD patients. Time-updated Cox regression modeling was used to test whether neuropsychological test scores, A140 levels, or a combination of both can predict conversion to MCI/AD in individuals who were cognitively normal at baseline. Logistic regression modeling was employed to construct receiver operator curves (ROC) to examine the predictive performance of neuropsychological measures and serum A140 levels. The sample had a mean age of 76.7 and mean education of 14.6, and was 98.1% Caucasian. Post hoc power calculations suggest a power of nearly 100% at the alpha value 0.05. This study found that the lowest quartiles of a142 and a142/a140 ratios were most predictive of conversion to MCI/AD. Neuropsychological testing combined with a142 and a142/a140 ratios had the highest sensitivity and specificity in predicting probabilities of Alzheimer's Disease, with an AUC of 0.91. \\n\\nCONCLUSION: This study provides evidence that a combination of brief neuropsychological tests and biomarkers can accurately predict risk of developing Mild Cognitive Impairment or Alzheimer's Disease in an at-risk cohort. Recent findings suggest that combining cognitive tests with blood biomarkers may be useful for predicting future MCI/AD at least 2-4 years prior to diagnosis. This study found that the combination of brief neuropsychological tests and blood biomarkers had higher sensitivities and specificities for predicting cognitive decline in at-risk cognitively normal older adults than either test alone. Further evaluation of this method is needed.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"BACKGROUND:\" + gpt_complete_custom_prompt(summary, make_abstract_prompt)\n",
    "# NOTE: We've added \"BACKGROUND:\" to the output text, as it is used as part of the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d8cc2b",
   "metadata": {},
   "source": [
    "**Looks pretty good!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066e6653",
   "metadata": {},
   "source": [
    "### Question-answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725772e",
   "metadata": {},
   "source": [
    "We can also ask specific questions about the text. Below are two custom prompts - the first for identifying the medical conditions and the second for identifying the main findings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6b5d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_conds_prompt(summary):\n",
    "    prompt = f\"Look at the following text and identify what medical conditions are mentioned. \\n \\n {summary} \\n \\n MEDICAL CONDITIONS:\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ebb78fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_findings_prompt(summary):\n",
    "    prompt = f\"Look at the following summary of a research study and identify what the main findings were. \\n \\n {summary} \\n \\n MAIN FINDINGS:\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8571415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The medical conditions mentioned in the paper are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" \\nAlzheimer's Disease (AD), Mild Cognitive Impairment (MCI), Amnestic Mild Cognitive Impairment (MCI), APOE4 allele\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The medical conditions mentioned in the paper are:\")\n",
    "gpt_complete_custom_prompt(summary, med_conds_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "623419aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main findings of the paper were:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Combining brief neuropsychological tests and blood biomarkers (A142 and A142/A140 ratios) had higher sensitivities and specificities for predicting cognitive decline in at-risk cognitively normal older adults than either test alone, with an accuracy of 91%. Low levels of serum A142 and A142/A140 ratios were associated with cognitive decline even within one year.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The main findings of the paper were:\")\n",
    "gpt_complete_custom_prompt(summary, main_findings_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c28c40a",
   "metadata": {},
   "source": [
    "This seems to be working pretty well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3c4abe",
   "metadata": {},
   "source": [
    "Your task: play around with other prompts for asking other questions. Come up with at least three other prompts for different aspects of the paper.\n",
    "\n",
    "What seems to work well and what not so well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab8763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write and test further prompts here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eb9ee5",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c568eb7",
   "metadata": {},
   "source": [
    "1. **Play around with different prompts for obtaining different information**. Check out [this course](https://learnprompting.org/docs/intro) if you want more guidance on how to generate prompts.\n",
    "\n",
    "2. **Try different models and compare them to the GPT model we used**. For this you can:\n",
    "    - Modify the \"model\" parameter when calling the \"openai.Completion.create()\" function\n",
    "    - Use a different API. For example, the [HuggingFace API](https://huggingface.co) is another popular API for large language models.\n",
    "    - Load in specific models and see how they perform. We used a general model here (GPT), but there are models fine-tuned for biomedical text such as [biomedLM](https://github.com/stanford-crfm/BioMedLM) and [bio-clinical-BERT](https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT). Read the documentation, implement them and compare their performance against more general models like above.\n",
    "\n",
    "3. **Look at performance metrics for NLP model performance**. How might we compare the generated abstracts with the real ones?\n",
    "4. **Try fine-tuning your model** for \"abstract generation\" on the whole dataset, to see if it's performance improves. Use the real paper abstracts as the \"ground truth\" training data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d7509",
   "metadata": {},
   "source": [
    "Fill out the form below and we'll provide feedback on your code.\n",
    "\n",
    "**Any feedback on the exercise? Any questions? Want feedback on your code? Please fill out the form [here](https://docs.google.com/forms/d/e/1FAIpQLSdoOjVom8YKf11LxJ_bWN40afFMsWcoJ-xOrKhMbfBzgxTS9A/viewform).**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
